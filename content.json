[{"title":"小玩requests及BeautifulSoup","date":"2017-03-24T02:15:08.000Z","path":"2017/03/24/requests文档阅读及使用/","text":"requests和BeautifulSoup是python爬虫非常重要的两个库,它们的使用非常简单,简单到我一直以来没有看过文档…今天突然想起看一看它们的文档,然后写了一个1024爬图片的demo,废话少说,上车! 1024对于老司机来说肯定是再熟悉不过了ｂ（￣▽￣）ｄ不过为了某些不可明说的因素,今天就不整那些太过于影响社会和谐的了,就简单的搞一搞新时代的我们里面的写真吧,不过…单单写真就火力很猛了… 别着急,图这就来 首先分析下帖子列表的页面,进入1024,点击新时代的我们,选取右上角的写真 F12分析下网页的结构 发现我们需要的内容都在一个class=”tal”下的h3的a里面,那我们就一句简单的 1soup.select('.tal h3 a') 之后列表解析 1[(a.get_text(), a['href']) for a in a_s] 就能获得一个包含了帖子标题和链接的元组列表了 接下来再分析下图片贴的页面,这里我们只需要获得图片的地址就行了: 发现它就在class=”tpc_content”下的input里面,那我们直接: 1soup.select(\".tpc_content input\") 就能获取所有的input了,之后只要取出里面的src属性就是图片的地址了,就可以使用open函数或者urllib.urlretrieve下载了哦 下面是全部代码:123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566#-*- coding:utf-8 -*-import osimport requestsfrom bs4 import BeautifulSoupfrom requests.exceptions import RequestExceptiondef get_page(url): try: response = requests.get(url, timeout=3) if response.status_code == 200: return response.content return None except RequestException: print '数据获取失败' return None#解析帖子列表页面,获取帖子标题以及链接def get_posts(url, i): #解析 soup = BeautifulSoup(get_page(url), 'html.parser') a_s = soup.select('.tal h3 a') #第一页无关帖子过滤 if i == 1: return [(a.get_text(), a['href']) for a in a_s][3:] else: return [(a.get_text(), a['href']) for a in a_s]#获取帖子里的图片并下载至本地def get_pictures(title, url): #创建名为帖子标题的文件夹 path = '/Users/**/Desktop/web_spider/driver/' + title is_exists = os.path.exists(path) if not is_exists: os.makedirs(path) print u'创建文件夹: ' + title #解析帖子页面 response = get_page(url) print u'获取' + title + u'贴成功!' soup = BeautifulSoup(response, 'html.parser') inputs = soup.select(\".tpc_content input\") pictures = [input_['src'] for input_ in inputs] for pic_url in pictures: download_picture(title, pic_url)#下载图片至本地def download_picture(title, url): picture = get_page(url) with open(u'/Users/**/Desktop/web_spider/driver/' + title + u'/' + url.split('/')[-1:][0], 'w+') as f: print url.split('/')[-1:][0] + u' 下载中...' try: f.write(picture) except: print url.split('/')[-1:][0] + u'下载失败'def main(): #未登录可以浏览前100页 for i in range(1, 101): url = 'http://******.***/thread0806.php?fid=8&amp;search=&amp;type=4&amp;page=' + str(i) for title, href in get_posts(url, i): print title, href get_pictures(title, 'http://******.***/' + href)if __name__ == '__main__': main() 网站地址以及个人信息都使用 * 替代了,相信老司机们都有自己的办法找到的~(≧▽≦)/~ ##有两个需要注意的点:BeautifulSoup解析器不要用lxml,我用的是html.parser,在使用lxml的时候不知为何解析不出文档来,查了下可能是lxml对结构不好的网站会直接不显示某些文档…这是不是打1024前端的脸啊… 然后是列表第一页会有几个置顶帖 这里我们用if判断一下去掉就好 最后我们跑一下… OK,这样我们就可以把新时代的我们里的写真主题的所有图片都下载到本地了","tags":[{"name":"爬虫","slug":"爬虫","permalink":"http://ZhuDiGit.github.io/tags/爬虫/"},{"name":"Python","slug":"Python","permalink":"http://ZhuDiGit.github.io/tags/Python/"}]},{"title":"使用hexo+github部署个人博客","date":"2017-03-21T09:04:37.000Z","path":"2017/03/21/使用hexo-github部署个人博客/","text":"背景:刚刚使用hexo+github布置完了自己的博客,从有这个想法到这篇blog发布大概用了两天的时间,遇到了挺多的坑…最早因为担心环境的坑想使用docker的,不过想了一下觉得坑肯定会更多…所以就放弃了,直接在电脑上装吧…就这样中间还因为敲错了一个字母而卡了一下午…丢人丢到姥姥家了… 环境:系统:macOSX 首先是git:这里更新一下Xcode就好了… 然后是nodejs:我使用的是homebrew,首先升级下homebrew 1$ brew update 然后是安装node 1$ brew install node --with-nmp 这个nmp貌似是跟pip和homebrew差不多的东西,包括接下来的hexo也是用它来安装的… 安装hexo1$ npm install -g hexo-cli 然后出现了这个 然后就根据提示 1$ npm install hexo --save ok 大功告成,环境就完事儿了 - hexo配置建立一个博客文件夹，并初始化博客，folder为文件夹的名称，可以随便起名字 1$ hexo init &lt;folder&gt; 进入博客文件夹，为文件夹的名称 1$ cd &lt;folder&gt; 然后输入node.js的命令，根据博客既定的dependencies配置安装所有的依赖包 1$ npm install 配置_config.yml12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273# Hexo Configuration## Docs: https://hexo.io/docs/configuration.html## Source: https://github.com/hexojs/hexo/# Sitetitle: 某人的blogsubtitle:description:author: language: zh-CNtimezone: Asia/Shanghai# URL## If your site is put in a subdirectory, set url as 'http://yoursite.com/child' and root as '/child/'url: http://你的github用户名.github.ioroot: /permalink: :year/:month/:day/:title/permalink_defaults:# Directorysource_dir: sourcepublic_dir: publictag_dir: tagsarchive_dir: archivescategory_dir: categoriescode_dir: downloads/codei18n_dir: :langskip_render:# Writingnew_post_name: :title.md # File name of new postsdefault_layout: posttitlecase: false # Transform title into titlecaseexternal_link: true # Open external links in new tabfilename_case: 0render_drafts: falsepost_asset_folder: falserelative_link: falsefuture: truehighlight: enable: true line_number: true auto_detect: false tab_replace:# Category &amp; Tagdefault_category: uncategorizedcategory_map:tag_map:# Date / Time format## Hexo uses Moment.js to parse and display date## You can customize the date format as defined in## http://momentjs.com/docs/#/displaying/format/date_format: YYYY-MM-DDtime_format: HH:mm:ss# Pagination## Set per_page to 0 to disable paginationper_page: 10pagination_dir: page# Extensions## Plugins: https://hexo.io/plugins/## Themes: https://hexo.io/themes/theme: landscape# Deployment## Docs: https://hexo.io/docs/deployment.htmldeploy: type: git repo: 你的项目地址 branch: master 主要是url和deploy那里要设置对了 接下来新建一篇文章: 1$ hexo new &quot;文章标题&quot; 然后在source文件夹里的_posts文件夹下就能找到.md的markdown文件了,编辑器有很多,我用的是macdown markdown语法还是挺简单的这里就不细说了 1$ hexo s 编辑完发布到本地先看看效果http://localhost:4000/ 然后CTRL + C退出,这里我们还要设置下git 1$ npm install hexo-deployer-git --save 最后就是部署啦! 1$ hexo d -g 成功!","tags":[{"name":"hexo","slug":"hexo","permalink":"http://ZhuDiGit.github.io/tags/hexo/"}]}]